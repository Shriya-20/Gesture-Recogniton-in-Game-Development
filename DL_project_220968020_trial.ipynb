{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d216be-d9ec-4553-9573-b8b6a28a980d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2e2297-95ad-41be-ae0b-77cfff02ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 15:53:43.183997: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-15 15:53:43.213450: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 15:53:43.703580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv3D, BatchNormalization, MaxPool3D, Dense, Flatten, Dropout, ConvLSTM2D, LSTM\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b788dcb-aeb2-4049-b287-7bccddf8fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/mca/anaconda3/envs/dse/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: scikit-image in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e182a7-caca-4db5-a633-e2b920131f87",
   "metadata": {},
   "source": [
    "##### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c4ac78-f39e-4058-b5ef-b5c3ccc0adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5915de8-4fc6-4fcf-986e-d8f203f2d296",
   "metadata": {},
   "source": [
    "#### Selecting Gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe57116-cc8a-4a0e-b7f0-694dc5d0de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29819, 2)\n",
      "        id                      labels\n",
      "7   136859                    Thumb Up\n",
      "8    68574               Swiping Right\n",
      "13   20706                  No gesture\n",
      "14   42237                  Thumb Down\n",
      "19  133442  Zooming Out With Full Hand\n",
      "(3640, 2)\n",
      "       id                     labels\n",
      "0    9223                   Thumb Up\n",
      "2   42920               Swiping Left\n",
      "3  106485                 Thumb Down\n",
      "6   35341  Zooming In With Full Hand\n",
      "7   94928              Swiping Right\n",
      "Csvs done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mca/anaconda3/envs/dse/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gesture_list = ['Swiping Right','Swiping Left','Thumb Up','Thumb Down','No gesture','Zooming In With Full Hand','Zooming Out With Full Hand']\n",
    "\n",
    "#train\n",
    "file_prefix = \"new_jester_3DCNN\"\n",
    "df = pd.read_csv('./annotations/jester-v1-train.csv',header=None,names=['id','labels'])\n",
    "df = df[df['labels'].isin(gesture_list)]\n",
    "df.to_csv('{}_train.csv'.format(file_prefix),sep=';',index=False)\n",
    "# pd.read_csv('jester-v1-8classes_train.csv',sep=\";\").head()\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "#val\n",
    "df = pd.read_csv('./annotations/jester-v1-validation.csv',sep=';',header=None,names=['id','labels'])\n",
    "df = df[df['labels'].isin(gesture_list)]\n",
    "df.to_csv('{}_val.csv'.format(file_prefix),sep=';',index=False)\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "print('Csvs done')\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, file_path, batch_size=2, image_dim=(256,256), frames_count=36, n_channels=1, base_dir='./20bn-jester-v1/', n_classes=27,validation=False):\n",
    "        self.image_dim = image_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = True \n",
    "        self.frames_count = frames_count\n",
    "        self.df = pd.read_csv(file_path,sep=\";\")\n",
    "        self.df.id = self.df.id.map(str)\n",
    "        if \"train\" in file_path:\n",
    "            self.encoder = OneHotEncoder(sparse=False)\n",
    "            self.encoder.fit(self.df.labels.values[:,None])\n",
    "            joblib.dump(self.encoder,\"{}_encoder_joblib.joblib\".format('_'.join(file_path.split('_')[:-1])))\n",
    "            np.save(\"encoder_classes_{}_npy.npy\".format(n_classes),self.encoder.categories_)\n",
    "        else:\n",
    "            self.encoder = joblib.load(\"{}_encoder_joblib.joblib\".format('_'.join(file_path.split('_')[:-1])))\n",
    "        self.base_dir = base_dir\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        ## Decides step_size\n",
    "        return self.df.shape[0] // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = self.df.loc[indexes,\"id\"].to_list()\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        return X, y \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.df.shape[0])\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        X = np.empty((self.batch_size,self.frames_count, *self.image_dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size,1), dtype=str)\n",
    "        y = []\n",
    "        for i, ID in enumerate(indexes):\n",
    "            files_list = self.standardize_frame_count(glob(self.base_dir + self.df.loc[ID,\"id\"] + \"/*.jpg\"),self.df.loc[ID])\n",
    "            for idx,filename in enumerate(files_list):\n",
    "                X[i,idx] = tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(filename,color_mode='grayscale',target_size=self.image_dim))\n",
    "            y.append(self.df.loc[ID,\"labels\"])\n",
    "        encoded = self.encoder.transform(np.array(y)[:,None])\n",
    "        return X,encoded\n",
    "        \n",
    "    def standardize_frame_count(self,files,error_check):\n",
    "        shape = len(files)\n",
    "        if shape < self.frames_count:\n",
    "            to_add = self.frames_count - shape\n",
    "            mid  = len(files)//2\n",
    "            dup = [files[mid]]*to_add\n",
    "            files = files[:mid] + dup + files[mid+1:]\n",
    "        elif shape > self.frames_count:\n",
    "            to_remove = (shape - self.frames_count)\n",
    "            to_remove = int(to_remove) if int(to_remove) == to_remove else int(to_remove) + 1\n",
    "            files = files[to_remove:]\n",
    "        return files\n",
    "    \n",
    "params = {'batch_size': 56,\n",
    "          'n_classes': len(gesture_list),\n",
    "          'n_channels': 3,\n",
    "          'image_dim': (32,32)\n",
    "          }\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(file_path=\"{}_train.csv\".format(file_prefix),**params)\n",
    "validation_generator = DataGenerator(file_path=\"{}_val.csv\".format(file_prefix),**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831e874b-54eb-4c42-84ba-fc9c9f54764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import joblib\n",
    "# from glob import glob\n",
    "\n",
    "# class DataGenerator(tf.keras.utils.Sequence):\n",
    "#     def __init__(self, file_path, batch_size=2, image_dim=(256, 256), frames_count=36,\n",
    "#                  n_channels=1, base_dir='./20bn-jester-v1/', n_classes=27, validation=False):\n",
    "#         self.image_dim = image_dim\n",
    "#         self.batch_size = batch_size\n",
    "#         self.n_channels = n_channels\n",
    "#         self.n_classes = n_classes\n",
    "#         self.shuffle = True \n",
    "#         self.frames_count = frames_count\n",
    "#         self.df = pd.read_csv(file_path, sep=\";\")\n",
    "#         self.df.id = self.df.id.map(str)\n",
    "\n",
    "#         if \"train\" in file_path:\n",
    "#             self.encoder = OneHotEncoder(sparse_output=False)\n",
    "#             self.encoder.fit(self.df.labels.values[:, None])\n",
    "#             joblib.dump(self.encoder, \"{}_encoder_joblib.joblib\".format('_'.join(file_path.split('_')[:-1])))\n",
    "#             np.save(\"encoder_classes_{}_npy.npy\".format(n_classes), self.encoder.categories_)\n",
    "#         else:\n",
    "#             self.encoder = joblib.load(\"{}_encoder_joblib.joblib\".format('_'.join(file_path.split('_')[:-1])))\n",
    "\n",
    "#         self.base_dir = base_dir\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.df.shape[0] // self.batch_size\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "#         X, y = self.__data_generation(indexes)\n",
    "#         return X, y \n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         self.indexes = np.arange(self.df.shape[0])\n",
    "#         if self.shuffle:\n",
    "#             np.random.shuffle(self.indexes)\n",
    "\n",
    "#     def __data_generation(self, indexes):\n",
    "#         X = np.empty((self.batch_size, self.frames_count, *self.image_dim, self.n_channels))\n",
    "#         y = []\n",
    "        \n",
    "#         for i, ID in enumerate(indexes):\n",
    "#             files_list = self.standardize_frame_count(glob(self.base_dir + self.df.loc[ID, \"id\"] + \"/*.jpg\"), self.df.loc[ID])\n",
    "            \n",
    "#             for idx, filename in enumerate(files_list):\n",
    "#                 if filename is not None:  # Check if filename is valid\n",
    "#                     X[i, idx] = tf.keras.preprocessing.image.img_to_array(\n",
    "#                         tf.keras.preprocessing.image.load_img(filename, color_mode='grayscale', target_size=self.image_dim)\n",
    "#                     )\n",
    "#                 else:\n",
    "#                     X[i, idx] = np.zeros((*self.image_dim, self.n_channels))  # Fill with zeros if no file\n",
    "\n",
    "#             y.append(self.df.loc[ID, \"labels\"])\n",
    "\n",
    "#         encoded = self.encoder.transform(np.array(y)[:, None])\n",
    "#         return X, encoded\n",
    "        \n",
    "#     def standardize_frame_count(self, files, error_check):\n",
    "#         shape = len(files)\n",
    "        \n",
    "#         if shape < self.frames_count:\n",
    "#             to_add = self.frames_count - shape\n",
    "#             if shape > 0:\n",
    "#                 mid = len(files) // 2\n",
    "#                 dup = [files[mid]] * to_add\n",
    "#                 files = files[:mid] + dup + files[mid + 1:]\n",
    "#             else:\n",
    "#                 files = [None] * self.frames_count  # Handle case with no files\n",
    "#         elif shape > self.frames_count:\n",
    "#             to_remove = shape - self.frames_count\n",
    "#             files = files[to_remove:]\n",
    "\n",
    "#         return files\n",
    "\n",
    "# # Parameters\n",
    "# params = {\n",
    "#     'batch_size': 56,\n",
    "#     'n_classes': len(gesture_list),\n",
    "#     'n_channels': 3,\n",
    "#     'image_dim': (32, 32)\n",
    "# }\n",
    "\n",
    "# # Generators\n",
    "# training_generator = DataGenerator(file_path=\"{}_train.csv\".format(file_prefix), **params)\n",
    "# validation_generator = DataGenerator(file_path=\"{}_val.csv\".format(file_prefix), **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab66d1-7f35-42f1-9c1a-4238acdd9454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191712c8-4738-444e-9e47-f99b9570b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv3D, BatchNormalization, MaxPool3D, Dense, Flatten, Dropout, ConvLSTM2D, LSTM\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a72375-bc06-4b27-9093-dabbd99f69c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660 Ti, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 15:53:51.276826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-15 15:53:51.294916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-15 15:53:51.295095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-15 15:53:51.295610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba56eb2-1fd3-49ad-9aaf-ba1d25632418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "532/532 [==============================] - 178s 332ms/step - loss: 1.6774 - accuracy: 0.4321 - val_loss: nan - val_accuracy: 0.1568\n",
      "Epoch 2/20\n",
      "532/532 [==============================] - 180s 338ms/step - loss: 1.0390 - accuracy: 0.6363 - val_loss: nan - val_accuracy: 0.1384\n",
      "Epoch 3/20\n",
      "532/532 [==============================] - 181s 339ms/step - loss: 0.8372 - accuracy: 0.7007 - val_loss: nan - val_accuracy: 0.1490\n",
      "Epoch 4/20\n",
      "532/532 [==============================] - 172s 322ms/step - loss: 0.7561 - accuracy: 0.7308 - val_loss: nan - val_accuracy: 0.1434\n",
      "Epoch 5/20\n",
      "532/532 [==============================] - 181s 340ms/step - loss: 0.6388 - accuracy: 0.7752 - val_loss: nan - val_accuracy: 0.1551\n",
      "Epoch 6/20\n",
      "396/532 [=====================>........] - ETA: 42s - loss: 0.5754 - accuracy: 0.7979"
     ]
    }
   ],
   "source": [
    "def build_model(n_classes=6):\n",
    "    momentum = 0.99\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv3D(64,kernel_size=3,strides=1,padding='valid',activation='elu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool3D(pool_size=(1, 2, 2), strides=(1,2,2),padding='same'))\n",
    "\n",
    "    model.add(Conv3D(128,kernel_size=3,strides=1,padding='valid',activation='elu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2,2,2),padding='same'))\n",
    "\n",
    "    model.add(Conv3D(256,kernel_size=3,strides=1,padding='valid',activation='elu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2,2,2),padding='same'))\n",
    "\n",
    "    model.add(Conv3D(256,kernel_size=3,strides=1,padding='valid',activation='elu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2,2,2),padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512,activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes,activation='softmax'))\n",
    "    #batch_size,n_classes\n",
    "    return model\n",
    "\n",
    "model = build_model(n_classes=len(gesture_list))\n",
    "optimizer = SGD(0.001)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "h=model.fit(training_generator,validation_data=validation_generator,validation_steps=32,epochs=20,verbose=1)\n",
    "\n",
    "def save_model(model,file_path):\n",
    "    model_json = model.to_json()\n",
    "    with open(file_path+'.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(file_path+'.h5')\n",
    "save_model(model,'{}_model'.format(file_prefix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460ebba-da07-4fe5-a8bb-7b41ed4ac24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(h.history['loss'],h.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610470b8-d2e1-464e-a3e3-e2cd736d651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(h.history['acc'],h.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e51866-da5b-472c-a8ad-4bc492655d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 20s 305ms/step - loss: nan - accuracy: 0.1464\n"
     ]
    }
   ],
   "source": [
    "h=model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e824e-5e8d-4054-93c9-dbeb2e66821f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
