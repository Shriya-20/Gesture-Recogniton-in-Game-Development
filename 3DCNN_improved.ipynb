{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d216be-d9ec-4553-9573-b8b6a28a980d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2e2297-95ad-41be-ae0b-77cfff02ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 12:06:07.696258: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 12:06:07.725331: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 12:06:08.237773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv3D, BatchNormalization, MaxPool3D, Dense, Flatten, Dropout, ConvLSTM2D, LSTM\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b788dcb-aeb2-4049-b287-7bccddf8fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/mca/anaconda3/envs/dse/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: scikit-image in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /home/mca/anaconda3/envs/dse/lib/python3.8/site-packages (from scikit-image) (0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e182a7-caca-4db5-a633-e2b920131f87",
   "metadata": {},
   "source": [
    "##### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c4ac78-f39e-4058-b5ef-b5c3ccc0adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5915de8-4fc6-4fcf-986e-d8f203f2d296",
   "metadata": {},
   "source": [
    "#### Selecting Gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe57116-cc8a-4a0e-b7f0-694dc5d0de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29819, 2)\n",
      "        id                      labels\n",
      "7   136859                    Thumb Up\n",
      "8    68574               Swiping Right\n",
      "13   20706                  No gesture\n",
      "14   42237                  Thumb Down\n",
      "19  133442  Zooming Out With Full Hand\n",
      "(3640, 2)\n",
      "       id                     labels\n",
      "0    9223                   Thumb Up\n",
      "2   42920               Swiping Left\n",
      "3  106485                 Thumb Down\n",
      "6   35341  Zooming In With Full Hand\n",
      "7   94928              Swiping Right\n",
      "Csvs done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mca/anaconda3/envs/dse/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gesture_list = ['Swiping Right','Swiping Left','Thumb Up','Thumb Down','No gesture','Zooming In With Full Hand','Zooming Out With Full Hand']\n",
    "\n",
    "#train\n",
    "file_prefix = \"new_jester_3DCNN\"\n",
    "df = pd.read_csv('./annotations/jester-v1-train.csv',header=None,names=['id','labels'])\n",
    "df = df[df['labels'].isin(gesture_list)]\n",
    "df.to_csv('{}_train.csv'.format(file_prefix),sep=';',index=False)\n",
    "# pd.read_csv('jester-v1-8classes_train.csv',sep=\";\").head()\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "#val\n",
    "df = pd.read_csv('./annotations/jester-v1-validation.csv',sep=';',header=None,names=['id','labels'])\n",
    "df = df[df['labels'].isin(gesture_list)]\n",
    "df.to_csv('{}_val.csv'.format(file_prefix),sep=';',index=False)\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "print('Csvs done')\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, file_path, batch_size=2, image_dim=(256,256), frames_count=36, n_channels=1, base_dir='./20bn-jester-v1/', n_classes=27,validation=False):\n",
    "        self.image_dim = image_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = True \n",
    "        self.frames_count = frames_count\n",
    "        self.df = pd.read_csv(file_path,sep=\";\")\n",
    "        self.df.id = self.df.id.map(str)\n",
    "        if \"train\" in file_path:\n",
    "            self.encoder = OneHotEncoder(sparse=False)\n",
    "            self.encoder.fit(self.df.labels.values[:,None])\n",
    "            joblib.dump(self.encoder,\"{}_encoder_joblib.joblib\".format('_'.join(file_path.split('_')[:-1])))\n",
    "            np.save(\"encoder_classes_{}_npy.npy\".format(n_classes),self.encoder.categories_)\n",
    "        else:\n",
    "            self.encoder = joblib.load(\"{}_encoder_joblib.joblib\".format('_'.join(file_path.split('_')[:-1])))\n",
    "        self.base_dir = base_dir\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        ## Decides step_size\n",
    "        return self.df.shape[0] // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = self.df.loc[indexes,\"id\"].to_list()\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        return X, y \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.df.shape[0])\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        X = np.empty((self.batch_size,self.frames_count, *self.image_dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size,1), dtype=str)\n",
    "        y = []\n",
    "        for i, ID in enumerate(indexes):\n",
    "            files_list = self.standardize_frame_count(glob(self.base_dir + self.df.loc[ID,\"id\"] + \"/*.jpg\"),self.df.loc[ID])\n",
    "            for idx,filename in enumerate(files_list):\n",
    "                X[i,idx] = tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(filename,color_mode='grayscale',target_size=self.image_dim))\n",
    "            y.append(self.df.loc[ID,\"labels\"])\n",
    "        encoded = self.encoder.transform(np.array(y)[:,None])\n",
    "        return X,encoded\n",
    "        \n",
    "    def standardize_frame_count(self,files,error_check):\n",
    "        shape = len(files)\n",
    "        if shape < self.frames_count:\n",
    "            to_add = self.frames_count - shape\n",
    "            mid  = len(files)//2\n",
    "            dup = [files[mid]]*to_add\n",
    "            files = files[:mid] + dup + files[mid+1:]\n",
    "        elif shape > self.frames_count:\n",
    "            to_remove = (shape - self.frames_count)\n",
    "            to_remove = int(to_remove) if int(to_remove) == to_remove else int(to_remove) + 1\n",
    "            files = files[to_remove:]\n",
    "        return files\n",
    "    \n",
    "params = {'batch_size': 56,\n",
    "          'n_classes': len(gesture_list),\n",
    "          'n_channels': 3,\n",
    "          'image_dim': (32,32)\n",
    "          }\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(file_path=\"{}_train.csv\".format(file_prefix),**params)\n",
    "validation_generator = DataGenerator(file_path=\"{}_val.csv\".format(file_prefix),**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831e874b-54eb-4c42-84ba-fc9c9f54764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import joblib\n",
    "# from glob import glob\n",
    "\n",
    "# class DataGenerator(tf.keras.utils.Sequence):\n",
    "#     def __init__(self, file_path, batch_size=2, image_dim=(256, 256), frames_count=36,\n",
    "#                  n_channels=1, base_dir='./20bn-jester-v1/', n_classes=27, validation=False):\n",
    "#         self.image_dim = image_dim\n",
    "#         self.batch_size = batch_size\n",
    "#         self.n_channels = n_channels\n",
    "#         self.n_classes = n_classes\n",
    "#         self.shuffle = True \n",
    "#         self.frames_count = frames_count\n",
    "#         self.df = pd.read_csv(file_path, sep=\";\")\n",
    "#         self.df.id = self.df.id.map(str)\n",
    "\n",
    "#         if \"train\" in file_path:\n",
    "#             self.encoder = OneHotEncoder(sparse_output=False)\n",
    "#             self.encoder.fit(self.df.labels.values[:, None])\n",
    "#             joblib.dump(self.encoder, \"{}_encoder_joblib.joblib\".format('_'.join(file_path.split('_')[:-1])))\n",
    "#             np.save(\"encoder_classes_{}_npy.npy\".format(n_classes), self.encoder.categories_)\n",
    "#         else:\n",
    "#             self.encoder = joblib.load(\"{}_encoder_joblib.joblib\".format('_'.join(file_path.split('_')[:-1])))\n",
    "\n",
    "#         self.base_dir = base_dir\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.df.shape[0] // self.batch_size\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "#         X, y = self.__data_generation(indexes)\n",
    "#         return X, y \n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         self.indexes = np.arange(self.df.shape[0])\n",
    "#         if self.shuffle:\n",
    "#             np.random.shuffle(self.indexes)\n",
    "\n",
    "#     def __data_generation(self, indexes):\n",
    "#         X = np.empty((self.batch_size, self.frames_count, *self.image_dim, self.n_channels))\n",
    "#         y = []\n",
    "        \n",
    "#         for i, ID in enumerate(indexes):\n",
    "#             files_list = self.standardize_frame_count(glob(self.base_dir + self.df.loc[ID, \"id\"] + \"/*.jpg\"), self.df.loc[ID])\n",
    "            \n",
    "#             for idx, filename in enumerate(files_list):\n",
    "#                 if filename is not None:  # Check if filename is valid\n",
    "#                     X[i, idx] = tf.keras.preprocessing.image.img_to_array(\n",
    "#                         tf.keras.preprocessing.image.load_img(filename, color_mode='grayscale', target_size=self.image_dim)\n",
    "#                     )\n",
    "#                 else:\n",
    "#                     X[i, idx] = np.zeros((*self.image_dim, self.n_channels))  # Fill with zeros if no file\n",
    "\n",
    "#             y.append(self.df.loc[ID, \"labels\"])\n",
    "\n",
    "#         encoded = self.encoder.transform(np.array(y)[:, None])\n",
    "#         return X, encoded\n",
    "        \n",
    "#     def standardize_frame_count(self, files, error_check):\n",
    "#         shape = len(files)\n",
    "        \n",
    "#         if shape < self.frames_count:\n",
    "#             to_add = self.frames_count - shape\n",
    "#             if shape > 0:\n",
    "#                 mid = len(files) // 2\n",
    "#                 dup = [files[mid]] * to_add\n",
    "#                 files = files[:mid] + dup + files[mid + 1:]\n",
    "#             else:\n",
    "#                 files = [None] * self.frames_count  # Handle case with no files\n",
    "#         elif shape > self.frames_count:\n",
    "#             to_remove = shape - self.frames_count\n",
    "#             files = files[to_remove:]\n",
    "\n",
    "#         return files\n",
    "\n",
    "# # Parameters\n",
    "# params = {\n",
    "#     'batch_size': 56,\n",
    "#     'n_classes': len(gesture_list),\n",
    "#     'n_channels': 3,\n",
    "#     'image_dim': (32, 32)\n",
    "# }\n",
    "\n",
    "# # Generators\n",
    "# training_generator = DataGenerator(file_path=\"{}_train.csv\".format(file_prefix), **params)\n",
    "# validation_generator = DataGenerator(file_path=\"{}_val.csv\".format(file_prefix), **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab66d1-7f35-42f1-9c1a-4238acdd9454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191712c8-4738-444e-9e47-f99b9570b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv3D, BatchNormalization, MaxPool3D, Dense, Flatten, Dropout, ConvLSTM2D, LSTM\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a72375-bc06-4b27-9093-dabbd99f69c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660 Ti, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 12:06:14.738353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:14.756893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:14.757083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:14.757703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba56eb2-1fd3-49ad-9aaf-ba1d25632418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 12:06:17.031631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:17.031825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:17.031903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:17.392973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:17.393120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:17.393198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 12:06:17.393270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4363 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-10-16 12:06:18.255989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  2/532 [..............................] - ETA: 3:01 - loss: 3.0996 - accuracy: 0.1429   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 12:07:21.448717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f41d40029b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-16 12:07:21.448759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-10-16 12:07:21.509535: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532/532 [==============================] - 238s 347ms/step - loss: 1.6425 - accuracy: 0.4551 - val_loss: 0.9992 - val_accuracy: 0.6546\n",
      "Epoch 2/50\n",
      "532/532 [==============================] - 181s 341ms/step - loss: 1.0391 - accuracy: 0.6310 - val_loss: 0.8823 - val_accuracy: 0.6842\n",
      "Epoch 3/50\n",
      "532/532 [==============================] - 182s 342ms/step - loss: 0.8360 - accuracy: 0.7034 - val_loss: 0.6868 - val_accuracy: 0.7600\n",
      "Epoch 4/50\n",
      "532/532 [==============================] - 176s 331ms/step - loss: 0.7153 - accuracy: 0.7481 - val_loss: 0.6489 - val_accuracy: 0.7628\n",
      "Epoch 5/50\n",
      "532/532 [==============================] - 177s 333ms/step - loss: 0.6403 - accuracy: 0.7736 - val_loss: 0.6343 - val_accuracy: 0.7757\n",
      "Epoch 6/50\n",
      "532/532 [==============================] - 177s 333ms/step - loss: 0.5657 - accuracy: 0.7983 - val_loss: 0.5476 - val_accuracy: 0.8108\n",
      "Epoch 7/50\n",
      "532/532 [==============================] - 182s 341ms/step - loss: 0.5091 - accuracy: 0.8206 - val_loss: 0.5984 - val_accuracy: 0.7952\n",
      "Epoch 8/50\n",
      "532/532 [==============================] - 178s 334ms/step - loss: 0.4623 - accuracy: 0.8399 - val_loss: 0.6721 - val_accuracy: 0.7768\n",
      "Epoch 9/50\n",
      "532/532 [==============================] - 178s 334ms/step - loss: 0.4134 - accuracy: 0.8552 - val_loss: 0.5444 - val_accuracy: 0.8170\n",
      "Epoch 10/50\n",
      "532/532 [==============================] - 171s 322ms/step - loss: 0.3743 - accuracy: 0.8689 - val_loss: 0.6002 - val_accuracy: 0.7991\n",
      "Epoch 11/50\n",
      "532/532 [==============================] - 174s 327ms/step - loss: 0.3407 - accuracy: 0.8806 - val_loss: 0.4731 - val_accuracy: 0.8354\n",
      "Epoch 12/50\n",
      "532/532 [==============================] - 185s 348ms/step - loss: 0.3113 - accuracy: 0.8913 - val_loss: 0.5210 - val_accuracy: 0.8331\n",
      "Epoch 13/50\n",
      "532/532 [==============================] - 184s 345ms/step - loss: 0.2778 - accuracy: 0.9045 - val_loss: 0.5346 - val_accuracy: 0.8186\n",
      "Epoch 14/50\n",
      "532/532 [==============================] - 177s 332ms/step - loss: 0.2660 - accuracy: 0.9082 - val_loss: nan - val_accuracy: 0.1440\n",
      "Epoch 15/50\n",
      "532/532 [==============================] - 179s 337ms/step - loss: 0.2265 - accuracy: 0.9249 - val_loss: nan - val_accuracy: 0.1529\n",
      "Epoch 16/50\n",
      "532/532 [==============================] - 185s 346ms/step - loss: 0.2017 - accuracy: 0.9331 - val_loss: nan - val_accuracy: 0.1395\n",
      "Epoch 17/50\n",
      "532/532 [==============================] - 176s 330ms/step - loss: 0.1775 - accuracy: 0.9435 - val_loss: nan - val_accuracy: 0.1557\n",
      "Epoch 18/50\n",
      "532/532 [==============================] - 182s 341ms/step - loss: 0.1641 - accuracy: 0.9482 - val_loss: nan - val_accuracy: 0.1518\n",
      "Epoch 19/50\n",
      "532/532 [==============================] - 175s 328ms/step - loss: 0.1434 - accuracy: 0.9556 - val_loss: nan - val_accuracy: 0.1512\n",
      "Epoch 20/50\n",
      "532/532 [==============================] - 177s 331ms/step - loss: 0.1289 - accuracy: 0.9608 - val_loss: nan - val_accuracy: 0.1479\n",
      "Epoch 21/50\n",
      "532/532 [==============================] - 175s 328ms/step - loss: 0.1109 - accuracy: 0.9681 - val_loss: nan - val_accuracy: 0.1429\n",
      "Epoch 22/50\n",
      "532/532 [==============================] - 177s 331ms/step - loss: 0.1005 - accuracy: 0.9723 - val_loss: nan - val_accuracy: 0.1434\n",
      "Epoch 23/50\n",
      "532/532 [==============================] - 180s 338ms/step - loss: 0.0913 - accuracy: 0.9746 - val_loss: nan - val_accuracy: 0.1429\n",
      "Epoch 24/50\n",
      "532/532 [==============================] - 178s 335ms/step - loss: 0.0822 - accuracy: 0.9776 - val_loss: nan - val_accuracy: 0.1395\n",
      "Epoch 25/50\n",
      "532/532 [==============================] - 175s 328ms/step - loss: 0.0720 - accuracy: 0.9815 - val_loss: nan - val_accuracy: 0.1445\n",
      "Epoch 26/50\n",
      "532/532 [==============================] - 177s 333ms/step - loss: 0.0637 - accuracy: 0.9843 - val_loss: nan - val_accuracy: 0.1462\n",
      "Epoch 27/50\n",
      "532/532 [==============================] - 179s 336ms/step - loss: 0.0596 - accuracy: 0.9855 - val_loss: nan - val_accuracy: 0.1367\n",
      "Epoch 28/50\n",
      "532/532 [==============================] - 175s 329ms/step - loss: 0.0580 - accuracy: 0.9857 - val_loss: nan - val_accuracy: 0.1585\n",
      "Epoch 29/50\n",
      "532/532 [==============================] - 178s 334ms/step - loss: 0.0490 - accuracy: 0.9887 - val_loss: nan - val_accuracy: 0.1390\n",
      "Epoch 30/50\n",
      "532/532 [==============================] - 176s 331ms/step - loss: 0.0653 - accuracy: 0.9811 - val_loss: nan - val_accuracy: 0.1518\n",
      "Epoch 31/50\n",
      "532/532 [==============================] - 171s 322ms/step - loss: 0.0417 - accuracy: 0.9911 - val_loss: nan - val_accuracy: 0.1456\n",
      "Epoch 32/50\n",
      "532/532 [==============================] - 177s 332ms/step - loss: 0.0381 - accuracy: 0.9922 - val_loss: nan - val_accuracy: 0.1479\n",
      "Epoch 33/50\n",
      "532/532 [==============================] - 179s 337ms/step - loss: 0.0341 - accuracy: 0.9934 - val_loss: nan - val_accuracy: 0.1512\n",
      "Epoch 34/50\n",
      "532/532 [==============================] - 177s 331ms/step - loss: 0.0309 - accuracy: 0.9944 - val_loss: nan - val_accuracy: 0.1490\n",
      "Epoch 35/50\n",
      "532/532 [==============================] - 181s 340ms/step - loss: 0.0299 - accuracy: 0.9948 - val_loss: nan - val_accuracy: 0.1501\n",
      "Epoch 36/50\n",
      "532/532 [==============================] - 172s 324ms/step - loss: 0.0263 - accuracy: 0.9955 - val_loss: nan - val_accuracy: 0.1468\n",
      "Epoch 37/50\n",
      "532/532 [==============================] - 177s 331ms/step - loss: 0.0246 - accuracy: 0.9959 - val_loss: nan - val_accuracy: 0.1468\n",
      "Epoch 38/50\n",
      "532/532 [==============================] - 179s 336ms/step - loss: 0.0233 - accuracy: 0.9962 - val_loss: nan - val_accuracy: 0.1456\n",
      "Epoch 39/50\n",
      "532/532 [==============================] - 174s 327ms/step - loss: 0.0226 - accuracy: 0.9961 - val_loss: nan - val_accuracy: 0.1367\n",
      "Epoch 40/50\n",
      "532/532 [==============================] - 179s 335ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: nan - val_accuracy: 0.1384\n",
      "Epoch 41/50\n",
      "532/532 [==============================] - 171s 321ms/step - loss: 0.0207 - accuracy: 0.9967 - val_loss: nan - val_accuracy: 0.1429\n",
      "Epoch 42/50\n",
      "532/532 [==============================] - 182s 342ms/step - loss: 0.0180 - accuracy: 0.9975 - val_loss: nan - val_accuracy: 0.1462\n",
      "Epoch 43/50\n",
      "532/532 [==============================] - 183s 343ms/step - loss: 0.0178 - accuracy: 0.9979 - val_loss: nan - val_accuracy: 0.1484\n",
      "Epoch 44/50\n",
      "532/532 [==============================] - 180s 338ms/step - loss: 0.0170 - accuracy: 0.9973 - val_loss: nan - val_accuracy: 0.1546\n",
      "Epoch 45/50\n",
      "532/532 [==============================] - 170s 320ms/step - loss: 0.0157 - accuracy: 0.9981 - val_loss: nan - val_accuracy: 0.1451\n",
      "Epoch 46/50\n",
      "532/532 [==============================] - 183s 344ms/step - loss: 0.0157 - accuracy: 0.9977 - val_loss: nan - val_accuracy: 0.1423\n",
      "Epoch 47/50\n",
      "532/532 [==============================] - 178s 334ms/step - loss: 0.0143 - accuracy: 0.9981 - val_loss: nan - val_accuracy: 0.1507\n",
      "Epoch 48/50\n",
      "532/532 [==============================] - 172s 324ms/step - loss: 0.0129 - accuracy: 0.9987 - val_loss: nan - val_accuracy: 0.1434\n",
      "Epoch 49/50\n",
      "532/532 [==============================] - 176s 330ms/step - loss: 0.0133 - accuracy: 0.9984 - val_loss: nan - val_accuracy: 0.1473\n",
      "Epoch 50/50\n",
      "532/532 [==============================] - 179s 336ms/step - loss: 0.0120 - accuracy: 0.9986 - val_loss: nan - val_accuracy: 0.1440\n"
     ]
    }
   ],
   "source": [
    "def build_model(n_classes=7):\n",
    "    momentum = 0.99\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv3D(64,kernel_size=3,strides=1,padding='valid',activation='elu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool3D(pool_size=(1, 2, 2), strides=(1,2,2),padding='same'))\n",
    "\n",
    "    model.add(Conv3D(128,kernel_size=3,strides=1,padding='valid',activation='elu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2,2,2),padding='same'))\n",
    "\n",
    "    model.add(Conv3D(256,kernel_size=3,strides=1,padding='valid',activation='elu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2,2,2),padding='same'))\n",
    "\n",
    "    model.add(Conv3D(256,kernel_size=3,strides=1,padding='valid',activation='elu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2,2,2),padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512,activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes,activation='softmax'))\n",
    "    #batch_size,n_classes\n",
    "    return model\n",
    "\n",
    "model = build_model(n_classes=len(gesture_list))\n",
    "optimizer = SGD(0.001)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "h=model.fit(training_generator,validation_data=validation_generator,validation_steps=32,epochs=50,verbose=1)\n",
    "\n",
    "def save_model(model,file_path):\n",
    "    model_json = model.to_json()\n",
    "    with open(file_path+'.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(file_path+'.h5')\n",
    "save_model(model,'{}_model'.format(file_prefix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05e51866-da5b-472c-a8ad-4bc492655d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 21s 317ms/step - loss: nan - accuracy: 0.1464\n"
     ]
    }
   ],
   "source": [
    "h=model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ca45f-8d8d-4783-b78c-0153c4397fc6",
   "metadata": {},
   "source": [
    "### issue\n",
    "val loss becoming nan, after 13th epoch\n",
    "\n",
    "If you're training for cross entropy, add a small number like 1e-8 to your output probability.\n",
    "\n",
    "Because log(0) is negative infinity, when your model trained enough the output distribution will be very skewed, for instance say I'm doing a 4 class output, in the beginning my probability looks like\n",
    "\n",
    "0.25 0.25 0.25 0.25\n",
    "but toward the end the probability will probably look like\n",
    "\n",
    "1.0 0 0 0\n",
    "And you take a cross entropy of this distribution everything will explode. The fix is to artifitially add a small number to all the terms to prevent this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88001d-3fd0-4ef0-83b9-7258a4b6f8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
